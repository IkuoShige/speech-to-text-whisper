その判断というのも、我々人間は自分の脳の中で何をやっているのかというのがその結果としてしか感じられないというのかな。ですから非常に不思議な感じがすると思います。何かを判断するとか、物を見たり聞いたりして認識をするなどを瞬時にやってのけてしまうので、どういうふうに脳が動いているのかというのを理解するのってあまり難しいんですけれども、そういうふうな神経細胞の活動が、それこそものすごい数、何十億とか集まって結果が出てくるということですから、ある意味でコンピューターの中の処理と似ているといえば似ていますよね。コンピューターの中で複雑な演算をする場合も、元を正せばそれは0と1の足し算であると、そういうものを組み合わせることで、かなり高度な計算が瞬時にできてしまうというように言っています。それでこれも有名なようなものだと思いますけれども、その脳神経細胞をモデル化すると、このような形になって、一つの細胞がこういう濃度というかユニットという形で表されますけれども、そこに複数の入力が入ってくる。そのそれぞれの入力に対して何らかの重み係数、ここがちょっと大事なんですけれども、あらかじめ学習されたような重み係数で荷重はをとる。そうしたときにある式位置、この絵ではθと書いてありますけれども、そのθを超えた場合に出力が1という数が出る。超えなければ何もしないという、そういうものをニューラルネットワークの基本になる神経細胞モデル、シグモイド関数といったりしますけれども、その元になっているのはもう全てがこれです。これが複数あるいはものすごくたくさん集まることで、ニューラルネットワーク、あるいは最近流行っている心臓学習のモデルが作られているということです。この重みの話というのは、実際に数値を持っている人は、間の中で出てきたと思うんですけれども、人間がやっている行動とか感覚とかとつなげて説明をすると、われわれって結構都合がいい生き物だと思います。皆さんも音にしろ目で見るものにしろ、今こうして目を開けて教室を眺めて、何を見ていますか?例えば私が今スライドにこう書いてあるからこれを見なさいというような指示を出すと、皆さんはスライドを見て確かにこういうのがあるなということを意識するけれども、そうじゃないです。人間というのは確かに意識をすると、たとえ目を開いたときにいろんなものが見えますよ。だけど、黒板が見えたり風が見えたり前の人の背中が見えたりいろんなものが見えているんだけれども、意識をしないと、それってもういつの間にかどのようになっちゃう?どのようになっちゃうというか、記憶すらしないです。例えば、電車に乗ってきた人は、電車に乗り込んで、たぶん乗っている電車の場合は前に人が立っていたと思いますけれども、その人何色の服着ていましたか?と聞いても知らないです。覚えてないですよね。覚えなそうとしても、そのようなものを確かに自分は見ていたはずなんだけれども、意識をすれば、この人すごくいいTシャツ着ているなということを気にした瞬間に、それが記憶に残るんです。そういう脳の機能というのは実は非常に大事で、仮にこれ、もし自分が見たもの、聞いたものが全部脳に蓄積されちゃうと思うと、あっという間に破綻しますよ。どうしていいか分からない。処理がしきれなくなるんだけれども、自分に必要な情報だけを記憶するといってもすぐ忘れますけど、どの辺をとって忘れちゃうか。だけど、強く印象に残ることとか、これは絶対に覚えておいてくださいと言われると、それだけ強く脳の中で、この絵でいうと重みの強くなるわけです。その入力に対しては、これ大事なんだと思った瞬間にダウンリマーが大きくなる。あるいは細胞全体でいうと、発生環境の変化がすごく大きくなる。そういうことをやってみていた。何か本当にすごいなと思うのは、これらを実験すると面白いです。音にしろ、形状とか目にしろ。そもそも音声認識なんですけど、これもとっきのお話ししますけど、今確かに、全然関係ない内職している人がいるときに、私が喋っていて、聞いてくれてますよ。聞いてくれてるということは、君たちは私が喋っている声がちゃんと耳から入って、音声認識をしているんだけれども、じゃあ何を聞いてくれているかというと、私が喋る一時期、一言一言ではなく、全ての音をちゃんと聞き取っていないんです。脳が処理しているのは、私が喋っている内容、話の内容というか概念を脳外視を受け取ったら終わるわけです。その証拠に、往復返しならできると思いますが、今私が喋っていることをそのまま往復返ししてくださいという指示を出せば、脳が聞いているときは、たぶん上手に真似ができると思うけれど、例えば1分も経たなくていいかな、30秒くらい私が喋り続けます。30秒経ったことで話をやめて、今私が喋った30秒をそっくりそのままリピートしてくださいと、これむちゃくちゃ難しいってことです。20秒くらい喋るって難しい。だけど、今30秒で喋ったことがどういうことかと言ってくださいというのが簡単だよ、たぶん聞いてるから。そういうことです。脳がやっている作業って実はそういうことなんだけれども、脳神経細胞の中の重みっていうのが生物学的にも、これはラットの実験とかである程度知性を持っている動物の実験でかなりわかってきているんですけれども、どういう原理なのか、それは学習によって獲得されるんだと思いますが、おそらく先天的に持っている何かもあるんで、細胞の働きとしてね。例えば危険な入力に対してはシュッと重みが縮むとか、何かありますよって我々の中で、見たくないものを見たときは目を逸らすとか、そういう反応って別に意識しているのかもしれないけれど、何か感謝的に熱いものを引っ込めるみたいなのが完全に感謝だよ、それが脳がやっていることなんです。脳がやらないことにはすればできない。鈍くなるとケガをしたりするというそういうことです。人間も動物で生き物ですから、自己の守るというのは無意識にそういう機能がつながっているはずです。今のお話は一般的にミラミネストワークの研究だという話でしたが、音声認識においてはどうかということを少しここでもざっと紹介しておきます。音声認識にニューラルネットワークが使えるんじゃないかという発想は結構昔からあったんですけれども、おそらく私の知る限りで最初に成功した例がこれですね。1989年のTDNN、タイムリレーニューラルネットワーク、日本語でいうと時間遅れニューラルネットワークというものですが、ちょっと訳をやって後で詳しくお話ししますけれども、この辺りから研究が始まったと言ってもいいのですが、実はこのTDNNの時もそうだったのですけれども、一見うまくいきそうで研究者がそこそこ飛びついたものの、やっぱりいろいろと推しをしてみるとそれほどうまくいかない。だからある程度のところで大多数の研究者は諦めて、やっぱり違う方法なんじゃないかという、そういうことの繰り返しです。研究って一般的にそうなのかもしれないですよね。うまくいくぞと思っても、なかなかそう簡単に一変にうまくはいかないので、こっちやったりあっちやったりということを繰り返して、少しずつ少しずつ良くなっている。ある意味で音声認識の世界もそういう試行錯誤が重ねられてきたわけです。それで細々といろんな取り組みが行われてきた中で、ちょっと注目を集めた方法が、この1995年頃のハイブリッドアプローチ。何がハイブリッドなのかというと、この授業で取り扱ってきたHMMとニューラルネットワークを何となく組み合わせてみようと。例えば入力として音響特徴量を入れるという話をこの授業でしてきましたが、その特徴量の代わりにニューラルネットワークの出力を使ったらどうだみたいなことを、いろんな研究者が行ってきました。これも後でお話しします。それからさらに5年ぐらい進んだところで、タンデムアプローチと呼ばれた方法も提案されてきました。ニューラルネットワークは今は真相学習が当たり前に行われていますけれども、この時点ではまだそんな深い構造が簡単に実現できない。計算能力的にもそれをとるための推移的にもということで、それでニューラルネットを階層的に連結する。つまり一つ一つは単純な構造のネットワークをいくつか連結することで、何かできるんじゃないのかなという取り組みも行われました。これも後ほど少しお話をします。それで走行している中で、これはもうご存知の人が多いかもしれませんが、2007年頃、2006年、7年、8年、これはどこの分野を基準にするかでちょっと前後しまして難しいんですが、おおむねその頃だと思ってくれればいいと思います。ディープラーニング、真相学習というものが大ブレイクを起こした。今でこそ音声認識でも当たり前に使われていますが、本当は画像認識のコンテスト、ここに書いたような非常に大がかりなコンテストの結果、ディープラーニングを使ったチームがものすごくいい成績を収めたということでブレイクしました。こういうコンテストは画像の世界でも音声の世界でも頻繁に行われていまして、ある主催者というのかな、中心になっている人たちが何らかのタスクを決めます。タスク自体は何でもいいんだと思いますけれども、音声認識の場合もですね、例えばある程度の規模のデータを集めてきておいて、この同じデータを使ってこういうタスク、こんなふうな認識をやってみてくださいというふうにして世界中の研究者に配るわけですね。時間を決めて、いつまでという期間を決めて、その間にみんなせっせとプログラムを作ったりですね、実験をして最終的な結果を公表する、一番いい成績を収めたチームが優勝みたいな、そういうコンテストがあります。もちろんそこでいかにずるいことをせずに、ずるいことをしてもすぐに推進されてわかってしまうので、他の研究者が推進できる形で結果を出すということで、みんな当然頑張りますので、それで研究力がどんどん伸びる、世界的にも人に合わせることで研究が伸びるという非常にいい取り組みだと思いますけれども、ここに書いたようなコンテストで、深層学習、ディープランニングが大ブレイクを起こした。このDNNを使った音声認識の方法というのがすぐさま発表されて、DNNとHMMとDNNを組み合わせるという方法が非常にうまくいきますよという形で、音声認識の世界にもいろいろネットワークがごく当たり前のように入ってきたわけです。一般的な話はここでここまでなんですけど、この後一つ一つご紹介を伺います。ちょっと私自身が関わってきたという意味もあるので、このスライドの最初にあるDTNNの話、それからハイブリッド感染の話に戻します。今から思うと、その講義はハイブリッドとか感染防止、確かに関連ですね。ハイブリッドと感染防止、定義によってどっちのどっちになり得ると思うんですけれども、ハイブリッドって便利な言葉ですね。オンライン授業をハイブリッドでやります。何かそれやるという感じが。これまでに私は謎なんだと。コロナの時のオンライン授業にいろいろ言葉が生まれましたよね。オンデマンド授業。オンデマンド授業の方が不思議だ。オンデマンドというのは別に、多分君らしき1年生くらいの時はまだ受けれました。オンデマンド授業って変じゃない?オンデマンド授業って動画が止まらないでそれを見る授業みたいに思われる。オンデマンドって本当の意味は、その場で、例えば、じゃあ今日何の話しようか皆さん何聞きたいですか。何聞きたいですか。3点聞いて。ではじゃあこういうテーマこういうテーマ。じゃあ今日は皆さんのリクエストに寄せてこういう話をします。というのがオンデマンド授業です。動画を見る時間の自由度に対してオンデマンドというのは本当におかしいなといまだに思っているんですけれども。だからそういう言葉っていうのは、なぜかねずくとすごく面白い。ハイブリッドってもう分かったようなのは分からないような。タンデムって言葉は後で喋るかもしれないけど、タンデムってあまり聞かないかもしれないけれども、タンデム自転車って何かあまり見ない。2人乗り自転車のことをタンデムバイス。2人乗り自転車ってなんか遊園地とかに椅子があったりするけど、要するに椅子が2つ付いてて2人乗り自転車ってことをタンデムバイス。つないでいくっていう意味でタンデム。こういう転転車がその時点で言葉を作るということにかけては、すごい賭けた人たちがたくさん世の中において、その人たちが伝え出すとしばらくその言葉が広がる。多分オンデマンド授業など誰かが思いついてさっきから広がったんだと思います。ちょっと2、3分続いて続きをお見せします。